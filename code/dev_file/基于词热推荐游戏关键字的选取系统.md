基于词热推荐游戏关键字选取系统

6-12-----6-13：构建数据分析开发环境，以及分布式应用平台
6-14-----6-15：导入数据，了解基本数据

1.数据表
2.数据处理
6-17：数据处理，将收集的数据处理成分析所需的数据（将关系数据转换为数值矩阵的形式，方便后面的聚类运算）
3.收索词的聚类处理   k-means 算法（被选）
在中文样本下聚类，实验采用了k-means算法和自组织神经
6-18----6-22:实验效果下的数据量：词汇记录8万，
采用K-means的聚类算法实现词的聚类，时间在100s以上，自组织神经网络效率较k-means 效率稍低，并且准确率，效果上没有k-means好。
6-22问题：完整的K-means的分析效率的问题是目前影响因素之一！
才测试阶段我们采用的是mini-batch K-means 高效，10万数据计算时间小于10s
4.聚类的描述采用DCF-DCL先描述后聚类，先聚类后描述算法结合来实现
6-23:描述时先统计词的在聚类中的出现频数，根据类簇的词的相似度以及词的频数计算出词在类簇中的重要性，选择重要性高的词作为类簇的类别描述。
统计词时对于长词我们将其看做时文档，采用文档分类的描述的方法，归类长词

对于词的相似性的计算会有较低的执行效率：6-24:
方法一：最直接效率最低的方法：就是对整个词集合计算相似度，时间复杂度为O（N×N）
改进版一：类簇内计算相似度，扫描数据，计算相似度，时间复杂度也是O（N×N/K）K为聚类数 在当前数据集计算时间提高近30%
改进版二：类簇内计算，并记录计算结果，对于已计算的组合，不再二次计算，时间复杂度也是O (N*N/K) ,较改进版一，在当前数据集计算效率提高近20%
6-24问题：目前在效率上还是比较慢的主要问题点之一。

选择

同类词的关联
6-27:目前对于词的关联项目主要可选的选择要素包含：词的热度、词的当前的searchCount 、词的标签、词的聚类相似度（即某一词在聚类的相似程度（目前想到的有平均相似度、聚类内的与其他各词的相似度之和））
个人理解：
//根据实际需要，调节各因素的权重
1.词的热度是表示：该词与APP的被收索到的可能性，词热值越高，被收索到的可能性越高
2.词的标签：每个词均有自己的genreID标签集合，根据标签的重要性可以确定词的重要性
3.词的聚类相似度：词在所在的聚类里相似度越高，词被选为该聚类的代表词汇可能性越高
4.词的searchCount （表示有多少应用app以该词作为keyWord）:个人暂时认为可能与词的竞争性相关，
   目前是选择竞争度高的还是竞争度低的词，作为聚类代表词，有待确定。优选竞争性小的。

6-28：
1.聚类出基础词库的类别;
2.计算找出计算词的所在词类簇;
3.通过核心关键词，选择与其相似度高的词作候选词;
4.从中选择词热在前15-20的词作为关键词.
目前实验选择的Top15的推荐词，经多次验证效果是满足需求的！

 6-28问题：
 对于数据组合以及分词的需要目前还是要考虑的问题！
 6-29:对于SOM自适应神经网络测试实现
 数据类型沿用之前的K-means数据
 学习方法的描述如下：
 1.初始化：对输入的各权向量赋小随机数，并进行归一化处理，建立初始化邻域和学习率初值
weight  :权值向量矩阵 （首先整个权值向量矩阵归一化，随后计算需要单条归一化）
k_cluster ：初始化的聚类数目，只是作为初始限定
iter_times ： 迭代次数（目前看并没什么卵用）
learn_deep ：学习率
stop_deep_val ：学习率下限（停止迭代的阀值）
2.接收输入
从训练集中取一输入样本，并进行归一化处理（可以提前对整个数据集进行归一化）
3.计算和寻找优胜节点
计算权值向量与样本向量的点积，找出点积最大的权值向量
4.计算优胜邻域
5.以该权值向量为中心调整在中心半径内的所有权值向量
6，计算学习率，结束判定.


